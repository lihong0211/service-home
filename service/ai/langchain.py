# service/ai/langchain.py
"""
LangGraph æ ¸å¿ƒåŠŸèƒ½å¯è§†åŒ–æ¼”ç¤º

æ¼”ç¤ºå†…å®¹ï¼š
1. å¾ªç¯ä¸åˆ†æ”¯ - åŸºç¡€åŠŸèƒ½ï¼ˆthink/decide å¾ªç¯ï¼‰
2. å¹¶è¡Œæ‰§è¡Œ - å¤šåˆ†æ”¯æ±‡èšï¼ˆæƒ…æ„Ÿ/å…³é”®è¯/æ‘˜è¦ â†’ èšåˆï¼‰
3. çŠ¶æ€ç®¡ç† - MemorySaver æŒä¹…åŒ–ä¸æ¢å¤
4. æ¡ä»¶è·¯ç”± - æ„å›¾è¯†åˆ«ä¸å¤šè·¯åˆ†å‘
5. äººæœºäº¤äº’èŠ‚ç‚¹ - AI å»ºè®® â†’ äººå·¥å®¡æ ¸ â†’ å¤„ç†åé¦ˆ
6. å®æ—¶æ‰§è¡Œç›‘æ§ - stream å¯è§†åŒ–ä¸ç®€å•ä»ªè¡¨ç›˜
"""

from __future__ import annotations

import operator
import time
from datetime import datetime
from typing import Annotated, TypedDict

# LangGraph å›¾ä¸çŠ¶æ€
from langgraph.graph import END, StateGraph
from langgraph.checkpoint.memory import MemorySaver

# ---------------------------------------------------------------------------
# 1. å¾ªç¯ä¸åˆ†æ”¯ - åŸºç¡€åŠŸèƒ½
# ---------------------------------------------------------------------------


class AgentState(TypedDict):
    messages: Annotated[list, operator.add]
    next_step: str
    iteration: int


def _think(state: AgentState) -> dict:
    print(f"ğŸ¤” æ€è€ƒä¸­... (ç¬¬{state['iteration']}è½®)")
    return {
        "messages": [f"æ€è€ƒè½®æ¬¡ï¼š{state['iteration']}"],
        "iteration": state["iteration"] + 1,
    }


def _decide(state: AgentState) -> dict:
    if state["iteration"] < 3:
        print("ğŸ”„ éœ€è¦ç»§ç»­æ€è€ƒï¼Œè¿›å…¥å¾ªç¯")
        return {"next_step": "think"}
    print("âœ… æ€è€ƒå®Œæˆï¼Œç»“æŸ")
    return {"next_step": END}


def build_loop_graph():
    """åˆ›å»ºå¸¦å¾ªç¯çš„å›¾ï¼šthink â†’ decide â†’ (think | END)ã€‚"""
    builder = StateGraph(AgentState)
    builder.add_node("think", _think)
    builder.add_node("decide", _decide)
    builder.set_entry_point("think")
    builder.add_edge("think", "decide")
    builder.add_conditional_edges(
        "decide",
        lambda s: s["next_step"],
        {"think": "think", END: END},
    )
    return builder.compile()


def demo_loop():
    """æ¼”ç¤ºå¾ªç¯æµç¨‹å›¾å¹¶æ‰“å° ASCII å›¾ã€‚"""
    graph = build_loop_graph()
    print("ğŸ“Š **å¾ªç¯æµç¨‹å›¾**")
    try:
        graph.get_graph().print_ascii()
    except Exception:
        print("  (å›¾ç»“æ„: think â†’ decide â†’ think æˆ– END)")
    print()
    # æ‰§è¡Œä¸€è½®æ¼”ç¤º
    out = graph.invoke(
        {"messages": [], "next_step": "", "iteration": 0}
    )
    print("æœ€ç»ˆçŠ¶æ€ iteration:", out.get("iteration"), "messages æ•°é‡:", len(out.get("messages", [])))
    return graph


# ---------------------------------------------------------------------------
# 2. å¹¶è¡Œæ‰§è¡Œ - å¤šåˆ†æ”¯æ±‡èšï¼ˆä½¿ç”¨ Send æˆ–é¡ºåºæ¨¡æ‹Ÿï¼‰
# ---------------------------------------------------------------------------


class ParallelState(TypedDict):
    input_text: str
    analyses: Annotated[list, operator.add]  # å¹¶è¡ŒèŠ‚ç‚¹ç”¨ append åˆå¹¶
    final_result: str


def _sentiment_analysis(state: ParallelState) -> dict:
    print("ğŸ”µ æƒ…æ„Ÿåˆ†æä¸­...")
    return {"analyses": [("sentiment", "positive")]}


def _keyword_extraction(state: ParallelState) -> dict:
    print("ğŸŸ¢ å…³é”®è¯æå–ä¸­...")
    return {"analyses": [("keywords", ["AI", "LangGraph"])]}


def _text_summary(state: ParallelState) -> dict:
    print("ğŸŸ  æ–‡æœ¬æ‘˜è¦ä¸­...")
    return {"analyses": [("summary", "è¿™æ˜¯æ‘˜è¦")]}


def _aggregate_results(state: ParallelState) -> dict:
    print("ğŸ“Š èšåˆæ‰€æœ‰åˆ†æç»“æœ")
    analyses = dict(state["analyses"]) if state.get("analyses") else {}
    return {"final_result": f"ç»¼åˆç»“æœï¼š{analyses}"}


def build_parallel_graph():
    """
    å¹¶è¡Œæ‰§è¡Œå›¾ï¼šå…¥å£åˆ†å‘åˆ° sentiment / keywords / summaryï¼Œå†æ±‡èšåˆ° aggregateã€‚
    è‹¥å½“å‰ç¯å¢ƒä¸æ”¯æŒ Sendï¼Œåˆ™ç”¨é¡ºåºè¾¹æ¨¡æ‹Ÿï¼ˆä¸‰èŠ‚ç‚¹ä¾æ¬¡æ‰§è¡Œååˆ° aggregateï¼‰ã€‚
    """
    builder = StateGraph(ParallelState)
    builder.add_node("sentiment", _sentiment_analysis)
    builder.add_node("keywords", _keyword_extraction)
    builder.add_node("summary", _text_summary)
    builder.add_node("aggregate", _aggregate_results)

    try:
        from langgraph.types import Send

        def _dispatch(state: ParallelState):
            return [Send("sentiment", state), Send("keywords", state), Send("summary", state)]

        builder.add_node("dispatch", lambda s: s)  # é€ä¼  state
        builder.set_entry_point("dispatch")
        builder.add_conditional_edges("dispatch", _dispatch)
        builder.add_edge("sentiment", "aggregate")
        builder.add_edge("keywords", "aggregate")
        builder.add_edge("summary", "aggregate")
    except ImportError:
        # æ—  Send æ—¶ï¼šé¡ºåºæ‰§è¡Œä¸‰èŠ‚ç‚¹å†èšåˆ
        builder.set_entry_point("sentiment")
        builder.add_edge("sentiment", "keywords")
        builder.add_edge("keywords", "summary")
        builder.add_edge("summary", "aggregate")

    builder.add_edge("aggregate", END)
    return builder.compile()


def demo_parallel():
    """æ¼”ç¤ºå¹¶è¡Œï¼ˆæˆ–é¡ºåºæ¨¡æ‹Ÿï¼‰æµç¨‹å›¾ã€‚"""
    graph = build_parallel_graph()
    print("ğŸ“Š **å¹¶è¡Œæ‰§è¡Œæµç¨‹å›¾**")
    try:
        graph.get_graph().print_ascii()
    except Exception:
        print("  (å›¾ç»“æ„: dispatch â†’ sentiment/keywords/summary â†’ aggregate â†’ END)")
    print()
    out = graph.invoke({"input_text": "ç¤ºä¾‹æ–‡æœ¬", "analyses": [], "final_result": ""})
    print("final_result:", out.get("final_result", "")[:80])
    return graph


# ---------------------------------------------------------------------------
# 3. çŠ¶æ€ç®¡ç† - MemorySaver æŒä¹…åŒ–
# ---------------------------------------------------------------------------


class ConversationState(TypedDict):
    messages: list
    context: dict
    user_info: dict
    tokens_used: int


def _process_message(state: ConversationState) -> dict:
    new_message = f"å¤„ç†æ¶ˆæ¯ #{len(state['messages']) + 1}"
    print(f"ğŸ’¬ {new_message}")
    return {
        "messages": state["messages"] + [new_message],
        "tokens_used": state.get("tokens_used", 0) + 10,
    }


def build_state_mgmt_graph():
    """å¸¦ checkpoint çš„å›¾ï¼Œç”¨äºæ¼”ç¤ºçŠ¶æ€æ¢å¤ã€‚"""
    builder = StateGraph(ConversationState)
    builder.add_node("process", _process_message)
    builder.set_entry_point("process")
    builder.add_edge("process", END)
    memory = MemorySaver()
    return builder.compile(checkpointer=memory)


def demo_state_management():
    """æ¼”ç¤ºçŠ¶æ€ç®¡ç†ï¼šåŒä¸€ thread_id ä¸‹ä¸¤æ¬¡ invoke ä¼šç´¯ç§¯ messagesã€‚"""
    graph = build_state_mgmt_graph()
    print("ğŸ“Š **çŠ¶æ€ç®¡ç†æ¼”ç¤º**")
    config = {"configurable": {"thread_id": "demo-thread-1"}}
    initial = {"messages": [], "context": {}, "user_info": {}, "tokens_used": 0}
    out1 = graph.invoke(initial, config)
    print("ç¬¬ä¸€æ¬¡æ‰§è¡Œ messages:", out1.get("messages"), "tokens_used:", out1.get("tokens_used"))
    out2 = graph.invoke(initial, config)
    print("ç¬¬äºŒæ¬¡æ‰§è¡Œï¼ˆå¸¦å†å²ï¼‰messages:", out2.get("messages"), "tokens_used:", out2.get("tokens_used"))
    return graph


# ---------------------------------------------------------------------------
# 4. æ¡ä»¶è·¯ç”± - æ„å›¾è¯†åˆ«ä¸å¤šè·¯åˆ†å‘
# ---------------------------------------------------------------------------


class RouterState(TypedDict):
    query: str
    intent: str
    response: str


def _classify_intent(state: RouterState) -> dict:
    query = (state.get("query") or "").lower()
    if "å¤©æ°”" in query:
        intent = "weather"
    elif "è‚¡ç¥¨" in query:
        intent = "stock"
    elif "æ–°é—»" in query:
        intent = "news"
    else:
        intent = "chat"
    print(f"ğŸ¯ æ„å›¾è¯†åˆ«: {intent}")
    return {"intent": intent}


def _weather_handler(state: RouterState) -> dict:
    return {"response": "â˜€ï¸ ä»Šå¤©å¤©æ°”æ™´æœ—ï¼Œ25åº¦"}


def _stock_handler(state: RouterState) -> dict:
    return {"response": "ğŸ“ˆ è‚¡å¸‚ä¸Šæ¶¨0.5%"}


def _news_handler(state: RouterState) -> dict:
    return {"response": "ğŸ“° ä»Šæ—¥å¤´æ¡ï¼šAIæ–°çªç ´"}


def _chat_handler(state: RouterState) -> dict:
    return {"response": "ğŸ’­ ä½ å¥½ï¼Œæˆ‘æ˜¯AIåŠ©æ‰‹"}


def build_router_graph():
    """æ¡ä»¶è·¯ç”±ï¼šclassify â†’ weather | stock | news | chat â†’ ENDã€‚"""
    builder = StateGraph(RouterState)
    builder.add_node("classify", _classify_intent)
    builder.add_node("weather", _weather_handler)
    builder.add_node("stock", _stock_handler)
    builder.add_node("news", _news_handler)
    builder.add_node("chat", _chat_handler)

    builder.set_entry_point("classify")
    builder.add_conditional_edges(
        "classify",
        lambda s: s["intent"],
        {"weather": "weather", "stock": "stock", "news": "news", "chat": "chat"},
    )
    for name in ["weather", "stock", "news", "chat"]:
        builder.add_edge(name, END)

    return builder.compile()


def demo_router():
    """æ¼”ç¤ºæ¡ä»¶è·¯ç”±å¹¶æ‰“å° ASCII å›¾ã€‚"""
    graph = build_router_graph()
    print("ğŸ“Š **æ™ºèƒ½è·¯ç”±æµç¨‹å›¾**")
    try:
        graph.get_graph().print_ascii()
    except Exception:
        print("  (å›¾ç»“æ„: classify â†’ weather|stock|news|chat â†’ END)")
    print()
    for q in ["ä»Šå¤©å¤©æ°”æ€ä¹ˆæ ·ï¼Ÿ", "æœ‰ä»€ä¹ˆæ–°é—»ï¼Ÿ", "éšä¾¿èŠèŠ"]:
        out = graph.invoke({"query": q, "intent": "", "response": ""})
        print(f"  query={q!r} â†’ response={out.get('response', '')}")
    return graph


# ---------------------------------------------------------------------------
# 5. äººæœºäº¤äº’èŠ‚ç‚¹ï¼ˆäººå·¥å®¡æ ¸ç”¨ mockï¼Œé¿å…é˜»å¡æœåŠ¡ï¼‰
# ---------------------------------------------------------------------------


class HumanInLoopState(TypedDict):
    task: str
    ai_suggestion: str
    human_feedback: str
    final_output: str


def _ai_analyze(state: HumanInLoopState) -> dict:
    print("ğŸ¤– AIåˆ†æä¸­...")
    time.sleep(0.2)
    suggestion = f"å»ºè®®æ–¹æ¡ˆï¼šå¤„ç† {state.get('task', '')}"
    print(f"ğŸ’¡ AIå»ºè®®ï¼š{suggestion}")
    return {"ai_suggestion": suggestion}


def _human_review(state: HumanInLoopState) -> dict:
    """æ¨¡æ‹Ÿäººå·¥å®¡æ ¸ï¼›ç”Ÿäº§ç¯å¢ƒå¯æ”¹ä¸º interrupt + å¤–éƒ¨è¾“å…¥ã€‚"""
    print("\nğŸ‘¤ === ç­‰å¾…äººå·¥å®¡æ ¸ï¼ˆæ­¤å¤„ç”¨ mockï¼‰===")
    print(f"AIå»ºè®®ï¼š{state.get('ai_suggestion', '')}")
    feedback = "approve"  # å¯æ”¹ä¸ºä»è¯·æ±‚/é˜Ÿåˆ—è¯»å–
    return {"human_feedback": feedback}


def _process_feedback(state: HumanInLoopState) -> dict:
    if state.get("human_feedback") == "approve":
        return {"final_output": state.get("ai_suggestion", "")}
    return {"final_output": "å·²æ ¹æ®äººå·¥åé¦ˆä¿®æ”¹"}


def build_human_loop_graph():
    """äººæœºåä½œï¼šanalyze â†’ review â†’ process â†’ ENDã€‚"""
    builder = StateGraph(HumanInLoopState)
    builder.add_node("analyze", _ai_analyze)
    builder.add_node("review", _human_review)
    builder.add_node("process", _process_feedback)
    builder.set_entry_point("analyze")
    builder.add_edge("analyze", "review")
    builder.add_edge("review", "process")
    builder.add_edge("process", END)
    return builder.compile()


def demo_human_loop():
    """æ¼”ç¤ºäººæœºåä½œæµç¨‹å›¾ã€‚"""
    graph = build_human_loop_graph()
    print("ğŸ“Š **äººæœºåä½œæµç¨‹å›¾**")
    try:
        graph.get_graph().print_ascii()
    except Exception:
        print("  (å›¾ç»“æ„: analyze â†’ review â†’ process â†’ END)")
    out = graph.invoke({"task": "å®¡æ ¸å·¥å•", "ai_suggestion": "", "human_feedback": "", "final_output": ""})
    print("final_output:", out.get("final_output"))
    return graph


# ---------------------------------------------------------------------------
# 6. å®æ—¶æ‰§è¡Œç›‘æ§ - stream å¯è§†åŒ–
# ---------------------------------------------------------------------------

NODE_ICONS = {
    "think": "ğŸ¤”",
    "decide": "ğŸ¯",
    "process": "âš™ï¸",
    "analyze": "ğŸ”",
    "generate": "âœ¨",
    "classify": "ğŸ¯",
    "aggregate": "ğŸ“Š",
    "weather": "â˜€ï¸",
    "stock": "ğŸ“ˆ",
    "news": "ğŸ“°",
    "chat": "ğŸ’­",
    "sentiment": "ğŸ”µ",
    "keywords": "ğŸŸ¢",
    "summary": "ğŸŸ ",
    "review": "ğŸ‘¤",
    "dispatch": "ğŸ“¤",
}

# èŠ‚ç‚¹ id -> å‰ç«¯å±•ç¤ºï¼ˆå¯é€‰è¦†ç›–ï¼‰ï¼Œæœªåˆ—å‡ºçš„ç”¨ raw_idã€type=process
NODE_DISPLAY = {
    "__start__": {"name": "ç”¨æˆ·è¾“å…¥", "type": "input", "icon": "ğŸ“", "description": "å…¥å£"},
    "__end__": {"name": "è¾“å‡º", "type": "output", "icon": "ğŸ“¢", "description": "å‡ºå£"},
    "classify": {"name": "æ„å›¾åˆ†ç±»", "type": "llm", "description": "åˆ†æç”¨æˆ·æ„å›¾"},
    "weather": {"name": "å¤©æ°”", "type": "tool", "description": "å¤©æ°”æŸ¥è¯¢"},
    "stock": {"name": "è‚¡ç¥¨", "type": "tool", "description": "è‚¡ç¥¨ä¿¡æ¯"},
    "news": {"name": "æ–°é—»", "type": "tool", "description": "æ–°é—»æ‘˜è¦"},
    "chat": {"name": "é—²èŠ", "type": "llm", "description": "é€šç”¨å¯¹è¯"},
    "think": {"name": "æ€è€ƒ", "type": "llm", "description": "è¿­ä»£æ€è€ƒ"},
    "decide": {"name": "å†³ç­–", "type": "condition", "description": "æ˜¯å¦ç»§ç»­"},
    "sentiment": {"name": "æƒ…æ„Ÿåˆ†æ", "type": "llm", "description": "æƒ…æ„Ÿåˆ†æ"},
    "keywords": {"name": "å…³é”®è¯", "type": "tool", "description": "å…³é”®è¯æå–"},
    "summary": {"name": "æ‘˜è¦", "type": "llm", "description": "æ–‡æœ¬æ‘˜è¦"},
    "aggregate": {"name": "èšåˆ", "type": "process", "description": "æ±‡æ€»ç»“æœ"},
    "analyze": {"name": "AI åˆ†æ", "type": "llm", "description": "ç”Ÿæˆå»ºè®®"},
    "review": {"name": "äººå·¥å®¡æ ¸", "type": "condition", "description": "äººå·¥ç¡®è®¤"},
    "process": {"name": "å¤„ç†åé¦ˆ", "type": "process", "description": "åº”ç”¨åé¦ˆ"},
}


def visualize_execution(graph, inputs: dict, sleep_sec: float = 0.3):
    """æŒ‰ stream æ­¥è¿›æ‰“å°æ¯ä¸ªèŠ‚ç‚¹çš„æ‰§è¡Œä¸çŠ¶æ€æ›´æ–°ã€‚"""
    print("ğŸ¬ **æ‰§è¡Œå¼€å§‹**")
    print("=" * 50)
    for step in graph.stream(inputs):
        for node_name, node_output in step.items():
            ts = datetime.now().strftime("%H:%M:%S")
            icon = NODE_ICONS.get(node_name, "ğŸ”¹")
            print(f"[{ts}] {icon} èŠ‚ç‚¹: {node_name}")
            print(f"   ğŸ“¦ çŠ¶æ€æ›´æ–°: {node_output}")
            print("-" * 30)
            if sleep_sec:
                time.sleep(sleep_sec)
    print("=" * 50)
    print("âœ… **æ‰§è¡Œå®Œæˆ**")


def get_node_color(status: str) -> str:
    """æŒ‰çŠ¶æ€è¿”å›ç»ˆç«¯é¢œè‰²ç ï¼ˆå¯é€‰ï¼Œç”¨äºé«˜çº§å¯è§†åŒ–ï¼‰ã€‚"""
    colors = {"active": "\033[92m", "completed": "\033[94m", "error": "\033[91m", "waiting": "\033[93m"}
    return colors.get(status, "\033[0m")


class LangGraphDashboard:
    """ç®€å•å†…å­˜ä»ªè¡¨ç›˜ï¼šè®°å½•æ‰§è¡Œè·¯å¾„ä¸èŠ‚ç‚¹çŠ¶æ€ã€‚"""

    def __init__(self):
        self.nodes_status: dict = {}
        self.execution_path: list = []

    def update(self, node_name: str, status: str, data=None):
        self.nodes_status[node_name] = {
            "status": status,
            "timestamp": datetime.now(),
            "data": data,
        }
        self.execution_path.append(node_name)

    def render(self, clear: bool = False):
        if clear:
            print("\033c", end="")
        print("â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—")
        print("â•‘   LangGraph å®æ—¶æ‰§è¡Œä»ªè¡¨ç›˜     â•‘")
        print("â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•")
        print("\nğŸ“ˆ æ‰§è¡Œè·¯å¾„:", " â†’ ".join(self.execution_path))
        print("\nğŸ“Š èŠ‚ç‚¹çŠ¶æ€:")
        for node, info in self.nodes_status.items():
            icon = "âœ…" if info["status"] == "completed" else "â³"
            print(f"  {icon} {node}: {info['status']}")
        print()


# ---------------------------------------------------------------------------
# å‰ç«¯ 3D å¯è§†åŒ–å¯¹æ¥ï¼šä»ç¼–è¯‘åçš„å›¾åŠ¨æ€ç”Ÿæˆ schemaï¼ˆä¾› React+Three.js ä½¿ç”¨ï¼‰
# ---------------------------------------------------------------------------

def _node_id_for_schema(raw_id: str) -> str:
    """å°†å›¾å†…éƒ¨èŠ‚ç‚¹ id è½¬ä¸ºå‰ç«¯ schema çš„ idï¼ˆ__start__ -> input, __end__ -> outputï¼‰ã€‚"""
    if raw_id == "__start__":
        return "input"
    if raw_id == "__end__":
        return "output"
    return raw_id


def graph_to_schema(compiled_graph, node_display: dict | None = None, node_icons: dict | None = None) -> dict:
    """
    ä» LangGraph ç¼–è¯‘åçš„å›¾åŠ¨æ€ç”Ÿæˆå‰ç«¯ GraphData æ ¼å¼ï¼šnodes + edgesã€‚
    ä½¿ç”¨ get_graph() çš„ nodes/edgesï¼Œä¸æ‰‹å†™ç»“æ„ã€‚
    node_display / node_icons å¯é€‰ï¼Œä¾›å…¶ä»–æ¨¡å—ï¼ˆå¦‚ agent_researchã€agent_wealth_advisorï¼‰ä¼ å…¥è‡ªå®šä¹‰å±•ç¤ºä¿¡æ¯ã€‚
    """
    raw = compiled_graph.get_graph()
    display_map = node_display if node_display is not None else NODE_DISPLAY
    icons_map = node_icons if node_icons is not None else NODE_ICONS
    nodes_out = []
    # èŠ‚ç‚¹ï¼šraw.nodes ä¸º dict[id -> Node]
    for raw_id in raw.nodes:
        display = display_map.get(raw_id, {})
        schema_id = _node_id_for_schema(raw_id)
        name = display.get("name") or raw_id
        node_type = display.get("type") or "process"
        icon = display.get("icon") or icons_map.get(raw_id, "ğŸ”¹")
        desc = display.get("description") or ""
        nodes_out.append({
            "id": schema_id,
            "name": name,
            "type": node_type,
            "icon": icon,
            "description": desc,
        })
    # è¾¹ï¼šraw.edges ä¸º list[Edge(source, target, data, conditional)]
    edges_out = []
    for e in raw.edges:
        src = getattr(e, "source", None) or (e.get("source") if isinstance(e, dict) else None)
        tgt = getattr(e, "target", None) or (e.get("target") if isinstance(e, dict) else None)
        src = _node_id_for_schema(src) if src else src
        tgt = _node_id_for_schema(tgt) if tgt else tgt
        conditional = getattr(e, "conditional", None)
        if conditional is None and isinstance(e, dict):
            conditional = e.get("conditional", False)
        edge_type = "conditional" if conditional else "normal"
        edges_out.append({"source": src, "target": tgt, "type": edge_type})
    return {"nodes": nodes_out, "edges": edges_out}


def run_graph_stream_and_collect(graph, state: dict):
    """
    æ‰§è¡Œå›¾ streamï¼Œæ”¶é›†æ¯ä¸€æ­¥çš„ nodeIdã€è€—æ—¶ã€è¾“å‡ºï¼Œä¾›å‰ç«¯æŒ‰çœŸå®æ‰§è¡Œé¡ºåºé©±åŠ¨å¯è§†åŒ–ã€‚
    è¿”å›ï¼š{"steps": [...], "finalState": {...}, "executionOrder": [...]}
    """
    steps = []
    execution_order = []
    t0 = time.perf_counter()
    for step in graph.stream(state):
        for node_id, output in step.items():
            t1 = time.perf_counter()
            duration_ms = round((t1 - t0) * 1000)
            t0 = t1
            steps.append({
                "nodeId": node_id,
                "status": "end",
                "duration_ms": duration_ms,
                "output": output,
            })
            execution_order.append(node_id)
    final_state = graph.invoke(state)
    return {
        "steps": steps,
        "finalState": final_state,
        "executionOrder": execution_order,
    }


GRAPH_BUILDERS = {
    "router": build_router_graph,
    "loop": build_loop_graph,
    "parallel": build_parallel_graph,
    "human_loop": build_human_loop_graph,
}

DEFAULT_INPUTS = {
    "router": {"query": "ä»Šå¤©å¤©æ°”æ€ä¹ˆæ ·ï¼Ÿ", "intent": "", "response": ""},
    "loop": {"messages": [], "next_step": "", "iteration": 0},
    "parallel": {"input_text": "ç¤ºä¾‹æ–‡æœ¬", "analyses": [], "final_result": ""},
    "human_loop": {"task": "å®¡æ ¸å·¥å•", "ai_suggestion": "", "human_feedback": "", "final_output": ""},
}


def get_graph_schema(name: str) -> dict | None:
    """ä»ç¼–è¯‘åçš„å›¾åŠ¨æ€ç”Ÿæˆå‰ç«¯ GraphDataï¼ˆnodes + edgesï¼‰ï¼Œä¸æ‰‹å†™ç»“æ„ã€‚"""
    builder_fn = GRAPH_BUILDERS.get(name)
    if not builder_fn:
        return None
    graph = builder_fn()
    schema = graph_to_schema(graph)
    schema["executionOrder"] = []  # çœŸå®é¡ºåºç”± POST /run è¿”å›
    return schema


def list_graph_names():
    """è¿”å›å¯ç”¨çš„å›¾åç§°åˆ—è¡¨ã€‚"""
    return list(GRAPH_BUILDERS.keys())


def run_graph_and_collect_steps(graph_name: str, input_state: dict | None = None):
    """
    æ‰§è¡ŒæŒ‡å®šå›¾ï¼Œæ”¶é›†æ¯ä¸€æ­¥çš„ nodeIdã€è€—æ—¶ã€è¾“å‡ºï¼Œä¾›å‰ç«¯æŒ‰çœŸå®æ‰§è¡Œé¡ºåºä¸èŠ‚å¥é©±åŠ¨ 3D åŠ¨ç”»ã€‚
    è¿”å›ï¼š{
        "graphData": { nodes, edges, executionOrder },
        "steps": [ { "nodeId", "status": "end", "duration_ms", "output" }, ... ],
        "finalState": { ... },
        "executionOrder": [ "classify", "weather", ... ]
    }
    """
    builder_fn = GRAPH_BUILDERS.get(graph_name)
    if not builder_fn:
        return {"error": f"æœªçŸ¥å›¾: {graph_name}", "allowed": list(GRAPH_BUILDERS.keys())}
    graph = builder_fn()
    state = input_state if input_state is not None else DEFAULT_INPUTS.get(graph_name, {})
    try:
        run_result = run_graph_stream_and_collect(graph, state)
    except Exception as e:
        return {"error": str(e)}
    schema = graph_to_schema(graph)
    return {
        "graphData": {
            "nodes": schema["nodes"],
            "edges": schema["edges"],
            "executionOrder": run_result["executionOrder"],
        },
        "steps": run_result["steps"],
        "finalState": run_result["finalState"],
        "executionOrder": run_result["executionOrder"],
    }


# ---------------------------------------------------------------------------
# å…¥å£ï¼šè¿è¡Œå…¨éƒ¨æ¼”ç¤º
# ---------------------------------------------------------------------------


def run_all_demos():
    """ä¾æ¬¡è¿è¡Œæ‰€æœ‰ LangGraph åŠŸèƒ½æ¼”ç¤ºã€‚"""
    print("\n" + "=" * 60)
    print("  LangGraph æ ¸å¿ƒåŠŸèƒ½å¯è§†åŒ–æ¼”ç¤º")
    print("=" * 60 + "\n")

    demo_loop()
    print()

    demo_parallel()
    print()

    demo_state_management()
    print()

    demo_router()
    print()

    demo_human_loop()
    print()

    # ç”¨è·¯ç”±å›¾åšä¸€æ¬¡ stream å¯è§†åŒ–
    router_graph = build_router_graph()
    print("ğŸ“Š **å®æ—¶æ‰§è¡Œç›‘æ§ç¤ºä¾‹ï¼ˆæ¡ä»¶è·¯ç”±ï¼‰**")
    visualize_execution(router_graph, {"query": "ä»Šå¤©å¤©æ°”æ€ä¹ˆæ ·ï¼Ÿ", "intent": "", "response": ""}, sleep_sec=0.2)
    print()

    print("ğŸ“Š **åŠŸèƒ½å¯¹æ¯”è¡¨**")
    print("| åŠŸèƒ½       | é€‚ç”¨åœºæ™¯           | å¤æ‚åº¦ |")
    print("|------------|--------------------|--------|")
    print("| å¾ªç¯       | è¿­ä»£ä¼˜åŒ–ã€å¤šè½®å¯¹è¯ | â­â­    |")
    print("| å¹¶è¡Œ       | æ‰¹é‡å¤„ç†ã€å¤šä»»åŠ¡   | â­â­â­   |")
    print("| æ¡ä»¶è·¯ç”±   | æ™ºèƒ½å®¢æœã€åˆ†ç±»å™¨   | â­â­    |")
    print("| äººæœºäº¤äº’   | å®¡æ ¸æµç¨‹ã€äººå·¥ä»‹å…¥ | â­     |")
    print("| çŠ¶æ€ç®¡ç†   | é•¿å¯¹è¯ã€å·¥ä½œæµ     | â­â­â­   |")


if __name__ == "__main__":
    run_all_demos()
